<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Shirley Blogs</title>
    <link>https://chenzheruc.github.io/posts/</link>
    <description>Recent content in Posts on Shirley Blogs</description>
    <generator>Hugo -- 0.150.1</generator>
    <language>en</language>
    <lastBuildDate>Sat, 06 Dec 2025 12:00:00 +0530</lastBuildDate>
    <atom:link href="https://chenzheruc.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Streaming Singularity: Unpacking Netflix’s $82.7 Billion Bet on Warner Bros</title>
      <link>https://chenzheruc.github.io/posts/20251206_netflix/</link>
      <pubDate>Sat, 06 Dec 2025 12:00:00 +0530</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251206_netflix/</guid>
      <description>&lt;p&gt;The entertainment world froze on Friday. In a move that redefines the concept of a &amp;ldquo;blockbuster,&amp;rdquo; Netflix has announced a definitive agreement to acquire Warner Bros. Discovery (WBD). This isn&amp;rsquo;t just a merger; it is the end of the Streaming Wars as we knew them and the beginning of a new, monopolistic era in Hollywood.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://chenzheruc.github.io/pic/20251206/netflix_1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you are trying to make sense of the headlines, here is the deep dive into what is actually happening, why it matters, and why this deal is far from a done deal.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Who is Adam?: The Question That Broke NeurIPS 2025</title>
      <link>https://chenzheruc.github.io/posts/20251206_adam/</link>
      <pubDate>Sat, 06 Dec 2025 10:00:00 +0530</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251206_adam/</guid>
      <description>&lt;p&gt;A reviewer, tasked with evaluating a technical submission for NeurIPS 2025—the most prestigious AI conference in the world—left a comment that will go down in infamy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Who is Adam?&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;For the uninitiated, asking &amp;ldquo;Who is Adam?&amp;rdquo; in a Deep Learning paper is akin to a mechanic asking &amp;ldquo;What is a wheel?&amp;rdquo; or a chef asking &amp;ldquo;What is salt?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Adam (Adaptive Moment Estimation) is arguably the most popular optimization algorithm in modern deep learning. It has been the default optimizer for nearly a decade. It is not a person the authors forgot to cite. It is not an obscure character in the paper&amp;rsquo;s narrative. It is the math that makes the models learn.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The 40-Point Inquisition: When AI Reviews AI at ICLR</title>
      <link>https://chenzheruc.github.io/posts/20251205_iclr/</link>
      <pubDate>Fri, 05 Dec 2025 23:00:00 +0530</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251205_iclr/</guid>
      <description>&lt;p&gt;In the high-stakes world of top-tier AI conferences like ICLR (International Conference on Learning Representations), getting a paper accepted is a career-defining moment. Authors spend months optimizing algorithms, ablation studies, and prose. They expect rigor. They expect tough questions.&lt;/p&gt;
&lt;p&gt;They do not expect 40 weaknesses and 40 questions from a single reviewer.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://chenzheruc.github.io/pic/20251205/iclr_1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;A recent incident involving an ICLR 2026 submission has set the Machine Learning community on fire, highlighting a growing crisis in academic peer review: the suspicion that AI is now reviewing AI, and doing a terrible job of it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Fork in the Road: Job Hunting as a Principal Engineer vs. Director</title>
      <link>https://chenzheruc.github.io/posts/20251205_job_hunt/</link>
      <pubDate>Fri, 05 Dec 2025 22:00:00 +0530</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251205_job_hunt/</guid>
      <description>&lt;p&gt;Job hunting at the executive or principal level is a fundamental departure from the standard engineering search. At this altitude, the goal is no longer to demonstrate competency in coding or sprint management. Instead, you must prove your capacity to move the needle for an entire organization. While the end goal—organizational impact—is shared, the mechanisms for proving your value differ wildly between the Individual Contributor (IC) track and the Management track.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The AI Scapegoat: Is AI Really Behind the Big Tech Layoffs?</title>
      <link>https://chenzheruc.github.io/posts/20251109_layoff/</link>
      <pubDate>Sun, 09 Nov 2025 15:00:54 +0530</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251109_layoff/</guid>
      <description>&lt;p&gt;If you follow the business world, you&amp;rsquo;ve heard the drumbeat. Scarcely a week goes by without a major tech company—be it Google, Amazon, Meta, or Microsoft—announcing a new round of &amp;ldquo;restructuring.&amp;rdquo; Thousands of jobs are cut, and amidst the corporate-speak about &amp;ldquo;streamlining&amp;rdquo; and &amp;ldquo;finding efficiencies,&amp;rdquo; a new two-letter buzzword has taken center stage: AI.&lt;/p&gt;
&lt;p&gt;The official narrative is compelling. We&amp;rsquo;re told that new generative AI tools are so powerful, so efficient, that the company can suddenly achieve more with fewer people. Roles in customer service, HR, recruiting, and even entry-level coding are being automated. The layoffs, therefore, are not a failure of management, but an inevitable, futuristic step in technological progress.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Geoffrey Hinton: They’re spending $420 billion on AI. It only pays off if they fire you</title>
      <link>https://chenzheruc.github.io/posts/20251109_hinton_ai/</link>
      <pubDate>Sun, 09 Nov 2025 09:00:00 +0530</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251109_hinton_ai/</guid>
      <description>&lt;p&gt;Geoffrey Hinton is the Nobel Prize-winning academic known as the “Godfather of AI” for his foundational work on neural networks. He spent decades at Google, building the very technology that now powers our world. Then, he quit. He left his high-paying role so he could speak freely about the dangers of the technology he helped create.&lt;/p&gt;
&lt;p&gt;His warnings have ranged from existential risk to the &amp;ldquo;end of humanity.&amp;rdquo; But in a recent, stunningly blunt interview, Hinton swapped his philosopher&amp;rsquo;s hat for a CFO&amp;rsquo;s visor. He didn’t talk about paperclip-maximizing terminators; he talked about simple, cold, hard capitalism.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Twilight of RAG: How LLM In-Context Ranking is Rewriting the Rules</title>
      <link>https://chenzheruc.github.io/posts/20251108_rag_is_dead/</link>
      <pubDate>Sat, 08 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251108_rag_is_dead/</guid>
      <description>&lt;p&gt;For the past few years, Retrieval-Augmented Generation (RAG) has been the cornerstone of scaling Large Language Models (LLMs) to massive knowledge bases. Since early LLMs suffered from limited input length—with models like GPT-4 handling only about 8,192 tokens (roughly 12 pages)—RAG provided an elegant, if complex, workaround: retrieve the most relevant fragments and feed those to the LLM.
However, the rapid evolution of LLMs and their specialized ranking capabilities, combined with exploding context windows, suggests that the traditional RAG architecture we built and optimized is fundamentally on the decline.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AGI is a Decade Away from Andrej Karpathy</title>
      <link>https://chenzheruc.github.io/posts/20251018_agi/</link>
      <pubDate>Sat, 18 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251018_agi/</guid>
      <description>&lt;p&gt;In September 2024, Sam Altman published &lt;a href=&#34;https://ia.samaltman.com/&#34;&gt;a blog post&lt;/a&gt; discussing &amp;ldquo;The Intelligence Age&amp;rdquo; and stated, &amp;ldquo;It is possible that we will have superintelligence in a few thousand days (!); it may take longer, but I&amp;rsquo;m confident we&amp;rsquo;ll get there&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;In the whirlwind of AI advancements, it&amp;rsquo;s easy to believe that Artificial General Intelligence (AGI) is just around the corner. Every week, a new model is released that shatters previous benchmarks, writes better code, or creates more realistic images. The hype cycle suggests we are on the precipice of a new dawn. Yet, one of the most respected minds in the field, Andrej Karpathy, recently poured a dose of realism on the fire, stating that  AGI is still &amp;ldquo;&lt;a href=&#34;https://www.youtube.com/watch?v=lXUZvyajciY&#34;&gt;a decade away.&lt;/a&gt;&amp;rdquo; &lt;/p&gt;</description>
    </item>
    <item>
      <title>Andrew Ng&#39;s Agentic AI Playbook</title>
      <link>https://chenzheruc.github.io/posts/20251016_andrew_ng_agentic_ai/</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251016_andrew_ng_agentic_ai/</guid>
      <description>&lt;p&gt;The world of AI is buzzing with a new paradigm: agentic AI. Instead of simply responding to a single prompt, these AI systems can reason, plan, use tools, and even critique their own work to accomplish complex, multi-step tasks. They represent a significant leap from the non-agentic models we&amp;rsquo;ve grown accustomed to.&lt;/p&gt;
&lt;p&gt;As this technology matures, building effective and reliable agents has become a critical skill. AI luminary Andrew Ng, through his &lt;a href=&#34;https://www.deeplearning.ai/courses/agentic-ai/&#34;&gt;Coursera courses&lt;/a&gt; published one week ago and &lt;a href=&#34;https://www.youtube.com/watch?v=KrRD7r7y7NY&#34;&gt;YouTube talks&lt;/a&gt;, has laid out a clear, practical framework for developing these intelligent systems. This playbook distills his key principles into actionable best practices for anyone looking to build the next generation of AI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Corporate Ladder is Crumbling: How AI is Forcing a Rethink of Tech Careers</title>
      <link>https://chenzheruc.github.io/posts/20251015_corporate_ladder/</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251015_corporate_ladder/</guid>
      <description>&lt;p&gt;For decades, the path to success in big tech, and corporate America at large, seemed straightforward: climb the ladder. You start as an individual contributor, become a senior, then a manager, a director, and so on. Each rung promised more responsibility, a better title, and a bigger paycheck. This system, a relic of a bygone industrial era, was designed for a world of predictable growth and top-down management.&lt;/p&gt;
&lt;p&gt;But that world is vanishing. Artificial intelligence is not just another tool; it&amp;rsquo;s a fundamental shift that will dismantle the very structure of the traditional corporate ladder. In the next 5-10 years, the way we think about career progression will be unrecognizable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Truman World to Real World: A Googler&#39;s Guide to StartUp </title>
      <link>https://chenzheruc.github.io/posts/20251011_whystartup/</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251011_whystartup/</guid>
      <description>&lt;p&gt;The experience of working at Google is a bit like living in &amp;ldquo;Truman World.&amp;rdquo; We operate within a beautifully constructed world with arguably the planet&amp;rsquo;s best technical infrastructure. Need a massively scalable database, a world-class deployment system, or a complex data analysis tool? There&amp;rsquo;s likely an internal API for that, polished and ready to go. Plus the people around are all filtered by the extermely rigurous interview process. But what happens when you decide to peek over the wall, to see what life is like on the outside with the dream of building something of your own?&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Idea to &#39;Vibe Code&#39;: Building a Kids&#39; Math App in a Few Hours</title>
      <link>https://chenzheruc.github.io/posts/20251008_vibe_coding/</link>
      <pubDate>Wed, 08 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251008_vibe_coding/</guid>
      <description>&lt;p&gt;It was one of those evenings. An idea sparked, and I just had to run with it.
The concept was simple: a clean, fun, and straightforward web app for kids to practice basic
addition and subtraction. No frills, no complicated sign-ups, just pure, simple math.
I wanted to see if I could go from a thought to a functional product in just a few hours.
This is the story of that little coding sprint.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Unseen Architects for Video Generation AI: Training Data</title>
      <link>https://chenzheruc.github.io/posts/20251002_videogen/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251002_videogen/</guid>
      <description>&lt;p&gt;Following the release of Sora 2 two days ago, Sam Altman has become widely recognized due to his frequent appearances in popular social media videos.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;In Shanghai&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;In Acient China&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Talks to a random person&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://chenzheruc.github.io/pic/20251002/sam_altman_1.png&#34;&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://chenzheruc.github.io/pic/20251002/sam_altman_2.png&#34;&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://chenzheruc.github.io/pic/20251002/sam_altman_3.png&#34;&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Sora 2 are gaining popularity; however, detailed public documentation regarding their underlying training methodologies remains scarce. OpenAI simply noted that Sora takes inspiration from large language models (LLMs) that acquire generalist capabilities by training on &amp;ldquo;&lt;a href=&#34;https://openai.com/index/video-generation-models-as-world-simulators/&#34;&gt;internet-scale data&lt;/a&gt;. It is possible that OpenAI may have scraped YouTube content without permission from Google. On the other hand, Google’s Veo is assumed to benefit from YouTube&amp;rsquo;s high-quality video. The implication is clear: the ability to generate realistic video is directly proportional to access to petabytes of high-quality, varied footage.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Roadblocks to AI Adoption: Key Challenges</title>
      <link>https://chenzheruc.github.io/posts/20251001_ai_system_challenges/</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://chenzheruc.github.io/posts/20251001_ai_system_challenges/</guid>
      <description>&lt;p&gt;Artificial intelligence systems are rapidly transforming the global economy, promising unprecedented efficiency, insight, and innovation. However, transitioning from AI&amp;rsquo;s theoretical potential to practical, ethical, and scalable application is fraught with significant challenges.&lt;/p&gt;
&lt;h2 id=&#34;ethical-and-trust-concerns&#34;&gt;Ethical and Trust Concerns&lt;/h2&gt;
&lt;p&gt;The most public and critical challenges surrounding AI revolve around how these powerful systems interact with human values, fairness, and accountability.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The Black Box Problem (Lack of Explainability)&lt;/strong&gt;. The &amp;ldquo;black box&amp;rdquo; nature of advanced AI, where decision-making logic is opaque to users and developers, creates the Explainable AI (XAI) crisis that prevents necessary auditing, justification, and trust in critical sectors like finance and healthcare.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
